{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from detail import Detail\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pylab\n",
    "import json\n",
    "import random\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "annFile='../../json/trainval_merged.json' # annotations\n",
    "imgDir='../../VOCdevkit/VOC2010/JPEGImages' # jpeg images\n",
    "phase='trainval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=7.54s)\n",
      "creating index...\n",
      "index created! 6.50s\n",
      "\n",
      "***info***\n",
      "description: This is the 3.0 version of the CVPR 2017 PASCAL in Detail dataset.\n",
      "version: 3.0\n",
      "year: 2017\n",
      "contributor: https://sites.google.com/view/pasd\n",
      "date_created: 2017-07-18\n"
     ]
    }
   ],
   "source": [
    "# initialize detail api for instance annotations\n",
    "detailsGt = Detail(annFile, imgDir, phase)\n",
    "\n",
    "print('\\n***info***')\n",
    "detailsGt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result json for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fake a result json for evaluation\n",
    "detaileval.gt_imgs\n",
    "detailRes = []\n",
    "count = 0\n",
    "for gt_img in detaileval.gt_imgs:\n",
    "    detailRes.append({'image_id': gt_img['image_id'], 'category_score': np.ndarray.tolist(np.zeros(59))})\n",
    "    if(2 in gt_img['categories']):\n",
    "        detailRes[-1]['category_score'][0] = 1\n",
    "    if(23 in gt_img['categories'] and count < 200):\n",
    "        count += 1\n",
    "        detailRes[-1]['category_score'][1] = 1\n",
    "    '''\n",
    "    for k in gt_img['categories']:\n",
    "        cat_idx = detaileval.cat_idxs[k]\n",
    "        detailRes[-1]['category_score'][cat_idx] = 1\n",
    "    '''\n",
    "result = {}\n",
    "result['pred'] = detailRes\n",
    "detail_res_file = '../results/detail_cls_fake_result.json'\n",
    "json.dump(result, open(detail_res_file, 'w'), indent = 4)\n",
    "detailRes = json.load(open('../results/detail_cls_fake_result.json', 'r'))['pred']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load evaluation module for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total category #59, total img #10100 \n"
     ]
    }
   ],
   "source": [
    "from detail import detaileval_cls \n",
    "from importlib import reload\n",
    "reload(detaileval_cls)\n",
    "detaileval = detaileval_cls.DetailEvalCls(details_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate annotation type cls\n",
      "{'category_id': 2, 'name': 'aeroplane', 'ap': 1.0}\n",
      "{'category_id': 23, 'name': 'bicycle', 'ap': 1.0}\n",
      "{'category_id': 25, 'name': 'bird', 'ap': 1.0}\n",
      "{'category_id': 31, 'name': 'boat', 'ap': 1.0}\n",
      "{'category_id': 34, 'name': 'bottle', 'ap': 1.0}\n",
      "{'category_id': 45, 'name': 'bus', 'ap': 1.0}\n",
      "{'category_id': 59, 'name': 'car', 'ap': 1.0}\n",
      "{'category_id': 65, 'name': 'cat', 'ap': 1.0}\n",
      "{'category_id': 72, 'name': 'chair', 'ap': 1.0}\n",
      "{'category_id': 98, 'name': 'cow', 'ap': 1.0}\n",
      "{'category_id': 397, 'name': 'diningtable', 'ap': 1.0}\n",
      "{'category_id': 113, 'name': 'dog', 'ap': 1.0}\n",
      "{'category_id': 207, 'name': 'horse', 'ap': 1.0}\n",
      "{'category_id': 258, 'name': 'motorbike', 'ap': 1.0}\n",
      "{'category_id': 284, 'name': 'person', 'ap': 1.0}\n",
      "{'category_id': 308, 'name': 'pottedplant', 'ap': 1.0}\n",
      "{'category_id': 347, 'name': 'sheep', 'ap': 1.0}\n",
      "{'category_id': 368, 'name': 'sofa', 'ap': 1.0}\n",
      "{'category_id': 416, 'name': 'train', 'ap': 1.0}\n",
      "{'category_id': 427, 'name': 'tvmonitor', 'ap': 1.0}\n",
      "{'category_id': 9, 'name': 'bag', 'ap': 1.0}\n",
      "{'category_id': 18, 'name': 'bed', 'ap': 1.0}\n",
      "{'category_id': 22, 'name': 'bench', 'ap': 1.0}\n",
      "{'category_id': 33, 'name': 'book', 'ap': 1.0}\n",
      "{'category_id': 44, 'name': 'building', 'ap': 1.0}\n",
      "{'category_id': 46, 'name': 'cabinet', 'ap': 0.99999999999999989}\n",
      "{'category_id': 68, 'name': 'ceiling', 'ap': 1.0}\n",
      "{'category_id': 80, 'name': 'cloth', 'ap': 1.0}\n",
      "{'category_id': 85, 'name': 'computer', 'ap': 1.0}\n",
      "{'category_id': 104, 'name': 'cup', 'ap': 1.0}\n",
      "{'category_id': 115, 'name': 'door', 'ap': 1.0}\n",
      "{'category_id': 144, 'name': 'fence', 'ap': 1.0}\n",
      "{'category_id': 158, 'name': 'floor', 'ap': 0.99999999999999989}\n",
      "{'category_id': 159, 'name': 'flower', 'ap': 1.0}\n",
      "{'category_id': 162, 'name': 'food', 'ap': 1.0}\n",
      "{'category_id': 187, 'name': 'grass', 'ap': 0.99999999999999989}\n",
      "{'category_id': 189, 'name': 'ground', 'ap': 1.0}\n",
      "{'category_id': 220, 'name': 'keyboard', 'ap': 1.0}\n",
      "{'category_id': 232, 'name': 'light', 'ap': 1.0}\n",
      "{'category_id': 259, 'name': 'mountain', 'ap': 1.0}\n",
      "{'category_id': 260, 'name': 'mouse', 'ap': 1.0}\n",
      "{'category_id': 105, 'name': 'curtain', 'ap': 1.0}\n",
      "{'category_id': 296, 'name': 'platform', 'ap': 1.0}\n",
      "{'category_id': 355, 'name': 'sign', 'ap': 1.0}\n",
      "{'category_id': 295, 'name': 'plate', 'ap': 1.0}\n",
      "{'category_id': 324, 'name': 'road', 'ap': 1.0}\n",
      "{'category_id': 326, 'name': 'rock', 'ap': 1.0}\n",
      "{'category_id': 349, 'name': 'shelves', 'ap': 1.0}\n",
      "{'category_id': 354, 'name': 'sidewalk', 'ap': 1.0}\n",
      "{'category_id': 360, 'name': 'sky', 'ap': 1.0}\n",
      "{'category_id': 366, 'name': 'snow', 'ap': 1.0}\n",
      "{'category_id': 19, 'name': 'bedclothes', 'ap': 1.0}\n",
      "{'category_id': 415, 'name': 'track', 'ap': 1.0}\n",
      "{'category_id': 420, 'name': 'tree', 'ap': 1.0}\n",
      "{'category_id': 424, 'name': 'truck', 'ap': 1.0}\n",
      "{'category_id': 440, 'name': 'wall', 'ap': 1.0}\n",
      "{'category_id': 445, 'name': 'water', 'ap': 1.0}\n",
      "{'category_id': 454, 'name': 'window', 'ap': 1.0}\n",
      "{'category_id': 458, 'name': 'wood', 'ap': 1.0}\n",
      "======= \n",
      " Mean ap over #59 categories 1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start evaluation\n",
    "detaileval.loadRes(detailRes)\n",
    "detaileval.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-test",
   "language": "python",
   "name": "py36-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
